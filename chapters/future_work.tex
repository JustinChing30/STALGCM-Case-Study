\chapter{Future Work}
\label{future_work}

This chapter discusses possible recommendations for future work on using formal language theory and the theory of computation in Filipino and Bikol Language grammar checkers.

\section{Context Sensitivity of Philippine Languages}

As evident in the common errors selected in Chapter \ref{errors}, these errors are relatively simple in nature. In other words, these are either specific cases of errors, or the errors selected are simple themselves. For instance, we can add the \textit{gitling} misuse for onomatopoeia in Chapter \ref{gitling_usage}, but this error is not included due to the complexity of the error.

 For that specific case, we need to take into account if the word is \textit{indeed} an onomatopoeia in $\mathcal{F}$, the syllables of that word, the vowel alterations, and other specifications.

 Another example is the CFG representation of the intensifying reduplication, like the phrase "kain nang kain". We can construct the CFG:

 \begin{center}
     \begin{tabular}{rcl}
         S & $\to$ &  V "nang" V \\ 
         V & $\to$ & "kain"
     \end{tabular}
 \end{center}

Having more than one non-terminal for the terminal V would result in the CFG:


 \begin{center}
     \begin{tabular}{rcl}
          S & $\to$ & V "nang" V \\
          V & $\to$ & "kain" | tulog
     \end{tabular}
 \end{center}

However, notice that this CFG will accept "kain nang kain" and "tulog nang tulog", but also "kain nang tulog" and "tulog nang kain" which are incorrect.

A bandage solution to this issue, and to allow us to create a CFG for this specific rule, we can say that we will have a CFG that has the non-terminal symbols S, V$_1$, V$_2$, $\dots$ V$_n$ where $n$ is the size of the set of verbs of $\mathcal{F}$ \cite{Seki_Matsumura_Fujii_Kasami_1991}. Or,

\begin{center}
    \begin{tabular}{rcl}
         S & $\to$ & V$_1$ "nang" V$_1$ $|$ V$_2$ "nang" V$_2$ $|$ $\dots$ $|$ V$_n$ "nang" V$_n$  \\
         V$_1$ & $\to$ & "kain" \\
         V$_2$ & $\to$ & "tulog" \\
         $\vdots$ & $\vdots$ & $\vdots$ \\
         V$_n$ & $\to$ & "takbo"
    \end{tabular}
\end{center}

Doing so will allow us to create a CFG that will accept the sentence structure $\omega \text{ nang } \omega$ where $\omega \in \mathcal{F}_\text{verbs}$. However, this is not very efficient as we will have $|\mathcal{F}_\text{verbs}| + 1$ the number of non-terminals and $2\times|\mathcal{F}_\text{verbs}|$ terminals.

Therefore, we need to add a constraint to a CFG, essentially creating an \textit{Attribute Grammar} \cite{kalita_kumar_roy_2022}. Doing so, we get

\begin{center}
    \begin{tabular}{rcll}
         S &$\to$& V$_1$ "nang" V$_2$ & : V$_1$, V$_2$ $\in$ V and V$_1$ = V$_2$  \\
         V &$\to$& "kain" $|$ "tulog" $| \cdots |$ "takbo" $|$ &
    \end{tabular}
\end{center}

Furthermore, introducing \textit{Context-Sensitive Grammars} will allow for the minimization of terminal and non-terminal symbols, making the grammar efficient \cite{Stabler_2004, Rawski_Dolatian_Heinz_Raimy_2023}. 

\section{Turing Machines, Turing Completeness, and Java}

It is the case that we need to extend the capability of CFGs or use automata that are strictly more powerful than CFGs. LanguageTool accomplished checking for errors that are at least as complex as the rule defined above through Java code \cite{LanguageToolDevDocs}.

It follows that, if a grammar rule cannot be expressed as a CFG, then expressing it as Java code is necessary since Java is \textit{Turing complete}. Thus, it is strictly more powerful than a CFG \cite{church_turing}.

Below are examples of grammar rules that are impossible or inefficient to implement as a CFG.

\paragraph{Kump and Kumb Words} If \(s\in \mathcal{S}\), and the prefix of \(s\) is given by the regular expression \((\texttt{C}\mid\texttt{c})\texttt{on}(\texttt{f}\mid\texttt{v})\). Then, the translation of $s$ to $\mathcal{F}$ or \(\mathcal{F}(s)\) is prefixed with \((\texttt{C}\mid\texttt{c})\texttt{um}(\texttt{p}\mid\texttt{b})\).

In particular:
\begin{itemize}
      \item \(\left(s \in (\texttt{conf})\mathbb{S}^*\right) \Longrightarrow \left(\mathcal{F}(s) \in (\texttt{kump})\Sigma^*\right)\)
      \item \(\left(s \in (\texttt{conv})\mathbb{S}^*\right) \Longrightarrow \left(\mathcal{F}(s) \in (\texttt{kumb})\Sigma^*\right)\)
\end{itemize}

\paragraph{Es- and Is- Words} Given the Spanish and English roots of Filipino, some \textit{loan} words have rules for Filipino spelling. Let \(s\) be any string, the English language \(\mathcal{E}\), the Spanish language \(\mathcal{S}\), and \(\mathcal{F}(s)\) be the translation of \(s\) in \(\mathcal{F}\).

\begin{enumerate}
      \item \(\left(\forall s\in \mathcal{S},s \in \texttt{es}\mathbb{S}^*\right) \Longrightarrow \left(\mathcal{F}(s) \in \texttt{es}\Sigma_\mathcal{F}^*\right) \)
      \item \(\left(\forall s\in \mathcal{E},s \in \texttt{s}\mathbb{E}^*\right) \Longrightarrow  \left(\mathcal{F}(s) \in \texttt{is} \Sigma_\mathcal{F}^* \right)\)
\end{enumerate}

Rule (1) denotes that if \(s\) is a Spanish word, translating \(s\) to a Filipino word would use \texttt{es} as the prefix to the word to denote that \(\mathcal{F}(s)\) is a word of Spanish origin. On the other hand, for rule (2), if \(s\) is an English word, then \(\mathcal{F}(s)\) would use \texttt{is} as the prefix to the word to denote that it is of English origin.

\paragraph{Onomatopeia} Let \( k \in \mathcal{F} \) be an onomatopoeic word given by:
\[
      k = s_0\texttt{-}s_1\texttt{-}\cdots\texttt{-}s_n 
\]
where \(\forall n, s_n \in \mathbb{O} \) represents an \textit{onomatopoeic syllable}, \( \mathbb{O} \) is the set of all such syllables \( n \geq 1 \), and each \( s_n \) is a single-syllable onomatopoeic unit. The word consists of at least two such syllables, separated by a \textit{gitling}.

\paragraph{Fifth Case of \texttt{Nang}} Used in between a repeated pandiwa.

\[
      S_5 = v_1 \cdot p \cdot \text{"nang"} \cdot p \cdot v_1
\]

\paragraph{Bikol Language: U-O Distribution for Reduplications}
Words that are a reduplication, or a joining of two syllables, can have the \texttt{u} sound at the end if and only if the reduplicated syllable does indeed have the \texttt{u} sound \cite{bikol_dictionary}.

Formally, any word given by the IEEE Posix regular expression:
\[
      \left( \Sigma_\mathbb{B}^*\texttt{u}\Sigma_\mathbb{B}^* \right)\backslash1 \in \mathcal{B}
\]

Below is an example implementation of the Pandiwa-Nang-Pandiwa grammar rule in LanguageTool using Java.

% Maximum source code width                                             |
\begin{lstlisting}[language=C, caption=Implementation of Pandiwa-Nang-Pandiwa Grammar Rule in Java]
import org.languagetool.AnalyzedSentence;
import org.languagetool.AnalyzedTokenReadings;
import org.languagetool.rules.Rule;
import org.languagetool.rules.RuleMatch;

import java.io.IOException; 
import java.util.ArrayList;
import java.util.List;

public class VerbNangVerbRule extends Rule {

    private static final String[] VERBS = {
        "mangyari", "gumawa", "sumulat", "tumakbo", 
        "kumain", "maglaro", "magbasa"  
        // a Pandiwa in Filipino
    };

    public VerbNangVerbRule(Language language) {
        List<Pattern> patterns = new ArrayList<>();
    }

    @Override
    public String getId() {
        return "VERB-NANG-VERB_RULE";
    }

    @Override
    public String getDescription() {
        return "A rule that detects errors in the phrase 
        structure VERB-Nang-VERB.";
    }

    @Override
    public RuleMatch[] match(AnalyzedSentence sentence) 
        throws IOException {
        List<RuleMatch> ruleMatches = new ArrayList<>();
        AnalyzedTokenReadings[] tokens = 
            sentence.getTokensWithoutWhitespace();

        for (int i = 1; i < words.length - 1; i++) {
            String prevWord = words[i - 1];
            String nextWord = words[i + 1];

            if ("nang".equals(words[i])) {
                // Check if the words surrounding "nang" 
                // are in the verbs array and are the same
                if (isVerb(prevWord) && 
                    isVerb(nextWord) && 
                    prevWord.equals(nextWord)) {
                    
                    RuleMatch ruleMatch = 
                        new RuleMatch(this, i, i + 2);
                    
                    ruleMatches.add(ruleMatch);

                    RuleMatch ruleMatch = new RuleMatch(
                            this,
                            sentence,
                            i - 1,
                            i + 1,
                            this.getMessage();
                    );
                    ruleMatches.add(ruleMatch);
                }
            }
        }

        return ruleMatches;
    }

    private boolean isVerb(String word) {
        for (String verb : VERBS) {
            if (verb.equals(word)) {
                return true;
            }
        }
        return false;
    }

    private String getMessage(){
        return "Pandiwa-Nang-Pandiwa misuse; the verbs 
                surrounding 'nang' must be the same.";
    }
}
\end{lstlisting}

In conclusion, this paper has explored the challenges and opportunities in using formal language theory, specifically Context-Free Grammars (CFGs) and regular expressions, for error checking in the grammar of Filipino and the Bikol language. We have discussed several common errors and provided various solutions, ranging from simple CFG representations, their CNF and GNF equivalents, to more advanced constructs like Attribute Grammars and Context-Sensitive Grammars, addressing the intricacies of the Philippine languages. Furthermore, we have highlighted the limitations of CFGs when confronted with complex grammatical rules and demonstrated how the power of Turing-complete programming languages, such as Java, can be leveraged to handle errors beyond the capabilities of CFGs.

As we move forward, integrating more sophisticated models for computation will be essential for further refining grammar checkers for Philippine languages. By combining formal language theory with machine learning techniques and natural language processing, future work can significantly enhance the accuracy and efficiency of Filipino grammar checkers, enabling a more nuanced understanding of language use and error detection.